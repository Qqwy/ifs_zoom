This document contains a semi-ordered set of notes and ideas,
which are stored here for safekeeping (combatting my forgetfulness) and percolating.

* Iterated Functions Zooming
** Info obtained from papers
*** All papers about IFS rendering target a 2D rasterized picture/texture
**** The main advantage here is that two points ending up in the same pixel do not take up more memory. In other words: Rendering 1M points to 100x100 pixels requires only to keep the 100x100 pixels in memory.
**** The immediate disadvantage is that it is impossible to zoom into this without seeing rendering artefacts.

*** All papers about IFS rendering read so far, with one exception (Green 2005 AKA 'GPU-accelerated IFS'), target rendering the IFS to a single, static image.
**** [Green05] re-renders the IFS at every frame using a 2D floating-point texture in a GPGPU algorithm.
***** This is because they desire to support arbitrary 'changing parameters over time'.
** New ideas
*** What about using a (2D) point cloud to store the points in?
**** Advantage: Re-usable regardless of zoom level.
**** Disadvantage: Takes more memory.
     Other notes: to speed up point-cloud -> pixelspace we might put the point cloud in e.g. a kD-tree.
     Other fancy techniques to work with point clouds exist (all of them targeting 3D rather than 2D however).
     They might be overkill (either too much work during bachelor's project, or too complex to speed up something based on the chaos game in the first place.)
*** Zooming 'out' when zoomed in far enough in self-similar IFS
**** This /requires/ self-similarity. For many IFSs this is true. Essentially only IFSs that are not contractive are not self-similar. 
     There are cases in which those non-contractive IFSs are used, for instance when creating a 'digest image' by driving a random number generator using a deterministic sequence on the non-contracting 'Square' IFS for fingerprints or DNA.
*** Using a point cloud stored in e.g. a kD-tree where we store information of contained points in each inner node.
    Idea is that this tree in many cases does not need to be evaluated all the way to individual points: if the points are closer to each-other than one pixel for a certain zoom-depth, we can stop early.

    On the other hand, if points are outside of camera range, we can drop them early from the search during rendering too.

* IFS rendering techniques
** Described:
*** The 'Deterministic Algorithm'
Described in 'Fractals Everywhere' and many other places.
*** (Nondeterministic) Chaos Game
Described in 'Fractals Everywhere' and many other places.
*** Deterministic Chaos Game based on 'de Bruijn' sequences (calculatable using finite fields).
Described in 'Fractals, Graphs, and Fields'
*** Optimizations on the 'Deterministic Algortihm' that do not iterate deeper than required. ("Adaptive Cut")
Is described in one of the paper 'Rendering Methods for Iterated Function Systems'. See pages 7-11 (section 2.1).
*** Ray-tracing using nested spheres
See section 2.5 of 'Rendering Methods for Iterated Function Systems'.

** Side notes
*** There are ways of obtaining better probability values for the chaos game using one of the deterministic algorithms.
    Is described in one of the paper 'Rendering Methods for Iterated Function Systems', section 2.4.
*** Contraction can be estimated
See section 2.2. of 'Rendering Methods'.

Perfect answer: `\rho(F) = sqrt(max(eigenvalues of transpose(A)*A))` where 'A' is the non-translation part of the affine transformation `F(x) = Ax+B`.
Rough but fast estimation: \rho(FG) = \rho(F)*\rho(G).
TODO comprehend intermediatly detailed estimation.

** New Ideas
*** The 'Penultimate(Squaring)' of my SPP can be used also to (deterministically) collapse the whole tree of iterated-transformations.
Since we however need to keep all possibilities, this will, for e.g. an IFS with 4 functions:
- (depth 0) single point
- (depth 1) 4 functions ('starting position')
- (depth 2) 16 functions (depth 1 * depth 1)
- (depth 4) 256 functions (depth 2 * depth 2)
- (depth 8) 65536 functions (depth 4 * depth 4)
- (depth 16) 4294967296 functions (depth 8 * depth 8) <- This might still be too low for many screens.
- (depth 32) 18446744073709551616 functions (depth 16 * depth 16) <- This is probably enough for most screens + zooms.
etc.

We might of course stop sooner which will still require log2(depth) steps to run but result in fewer functions.

Interestingly we do not need to keep the functions at the final layer in memory, since we can forget a function at the final depth once we have computed it and used it on a single point.

We might maybe be able to remove functions from the 'go-deeper' part when we find out that they are alraedy so contractive that they'd map to e.g. a single pixel?
